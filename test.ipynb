{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "path_to_home = \"../\"\n",
    "#path_to_home = \"./drive/MyDrive/receiptlayoutlm/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LayoutLMv2Tokenizer'. \n",
      "The class this function is called from is 'LayoutXLMTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv2FeatureExtractor, LayoutXLMTokenizer, LayoutXLMProcessor\n",
    "from transformers import LayoutLMv2ForTokenClassification\n",
    "\n",
    "feature_extractor = LayoutLMv2FeatureExtractor()\n",
    "tokenizer_xlm = LayoutXLMTokenizer.from_pretrained(\"microsoft/layoutxlm-base\")\n",
    "#processor_xlm = LayoutXLMProcessor(feature_extractor, tokenizer_xlm)\n",
    "model = LayoutLMv2ForTokenClassification.from_pretrained(\"sibrun/receiptlayoutlm\", use_auth_token=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def labeled_tokens_to_labeled_words(tokens, token_inds, ner_token_labels):\n",
    "        words = []\n",
    "        ner_labels = []\n",
    "        tokens_for_word = []\n",
    "        for t, i, l in zip(tokens, token_inds, ner_token_labels):\n",
    "                if t == \"<s>\":\n",
    "                        continue\n",
    "                if t == \"</s>\":\n",
    "                        words.append(tokenizer_xlm.convert_tokens_to_string(tokens_for_word))\n",
    "                        break\n",
    "                if i == -100:\n",
    "                        tokens_for_word.append(t)\n",
    "                        continue\n",
    "                ner_labels.append(l)\n",
    "                if len(tokens_for_word) == 0:\n",
    "                        tokens_for_word.append(t)\n",
    "                        continue\n",
    "                words.append(tokenizer_xlm.convert_tokens_to_string(tokens_for_word))\n",
    "                tokens_for_word = [t]\n",
    "        return words, ner_labels\n",
    "\n",
    "def get_labels_dict(words, ner_labels):\n",
    "        df = pd.DataFrame([words, ner_labels], index=[\"words\", \"tags\"]).T\n",
    "        labels_dict = {}\n",
    "        keys = list(model.config.label2id.keys())\n",
    "        for key in keys[1:]:\n",
    "                entity_words = df.query('tags==\"{}\"'.format(key))[\"words\"].tolist()\n",
    "                entity = \" \".join(entity_words)\n",
    "                entity = entity if len(entity)>0 else None\n",
    "                labels_dict[key] = entity\n",
    "        return labels_dict\n",
    "\n",
    "def extract_labels(image):\n",
    "        features = feature_extractor(image, return_tensors=\"pt\")\n",
    "        tokenizer_output = tokenizer_xlm(\n",
    "                text=features['words'],\n",
    "                boxes=features['boxes'],\n",
    "                word_labels=[list(range(len(features['words'][0])))],\n",
    "                is_split_into_words=True,\n",
    "                truncation=True,\n",
    "                return_tensors='pt')\n",
    "        model_input = tokenizer_output\n",
    "        token_inds = model_input.pop('labels')\n",
    "        model_input['image'] = features['pixel_values']\n",
    "        with torch.no_grad():\n",
    "                model_output = model(**model_input)\n",
    "        logits = model_output.logits.numpy()[0]\n",
    "        predictions = np.argmax(logits, axis=-1).tolist()\n",
    "        ner_token_labels = [model.config.id2label[p] for p in predictions]\n",
    "        tokens = [tokenizer_xlm.convert_ids_to_tokens(id) for id in model_input['input_ids'][0].tolist()]\n",
    "        token_inds = token_inds.tolist()[0]\n",
    "        words, ner_labels = labeled_tokens_to_labeled_words(tokens, token_inds, ner_token_labels)\n",
    "        labels_dict = get_labels_dict(words, ner_labels)\n",
    "        return labels_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/PycharmProjects/receiptlayoutlm/venv/lib/python3.9/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py:772: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.arange(\n",
      "/Users/simon/PycharmProjects/receiptlayoutlm/venv/lib/python3.9/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py:782: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.arange(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': 'NO 122.124. JALAN DEDAP 13 81100 JOHOR BAHRU', 'company': None, 'date': None, 'total': '80.90 80.91'}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "path_to_image = \"../data/X00016469622.jpg\"\n",
    "image = Image.open(path_to_image)\n",
    "labels_dict = extract_labels(image)\n",
    "print(labels_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}