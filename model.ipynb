{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import Repository"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_to_home = \"../\"\n",
    "#path_to_home = \"./drive/MyDrive/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/PycharmProjects/receiptlayoutlm/code/../hugging_face_repo is already a clone of https://huggingface.co/sibrun/receiptlayoutlm. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "hf_repo = Repository(path_to_home + \"hugging_face_repo\", clone_from=\"https://huggingface.co/sibrun/receiptlayoutlm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "hf_repo = Repository(path_to_home + \"hugging_face_repo\")\n",
    "#hf_repo.git_pull()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'image': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='uint8', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),\n 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n 'bbox': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "ds_receipts = load_from_disk(path_to_home + \"datasets/ds_receipts_final\")\n",
    "#ds_receipts = load_dataset(\"sibrun/receipts\", use_auth_token=True)\n",
    "ds_receipts['train'].features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from datasets import Features, Array2D, Array3D, Sequence, Value\n",
    "max_length = 512\n",
    "features = Features({\n",
    "    'image': Array3D(dtype=\"uint8\", shape=(3, 224, 224)),\n",
    "    'input_ids': Sequence(feature=Value(dtype=\"int32\"), length=max_length),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(max_length, 4)),\n",
    "    'labels': Sequence(feature=Value(dtype=\"int64\"), length=max_length),\n",
    "    'attention_mask': Sequence(feature=Value(dtype=\"int8\"), length=max_length),\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../datasets/ds_receipts_final/train/cache-e5c271fb43f54ac8.arrow\n",
      "Loading cached processed dataset at ../datasets/ds_receipts_final/test/cache-c1bc42bb40029ecf.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'image': Array3D(shape=(3, 224, 224), dtype='uint8', id=None),\n 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=512, id=None),\n 'bbox': Array2D(shape=(512, 4), dtype='int64', id=None),\n 'labels': Sequence(feature=Value(dtype='int64', id=None), length=512, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=512, id=None)}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_receipts = ds_receipts.cast(features)\n",
    "ds_receipts['train'].features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "label_names = ['company', 'date', 'address', 'total']\n",
    "labels = ['O'] + label_names\n",
    "num_labels = len(labels)\n",
    "ids_to_labels = {k: v for k, v in enumerate(labels)}\n",
    "labels_to_ids = {v: k for k, v in enumerate(labels)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from transformers import LayoutLMv2ForTokenClassification\n",
    "\n",
    "xlm_config = AutoConfig.from_pretrained(\"microsoft/layoutxlm-base\",\n",
    "                                         num_labels=num_labels,\n",
    "                                         id2label=ids_to_labels,\n",
    "                                         label2id=labels_to_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutxlm-base were not used when initializing LayoutLMv2ForTokenClassification: ['layoutlmv2.visual.backbone.bottom_up.res4.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.stem.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv1.norm.num_batches_tracked']\n",
      "- This IS expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LayoutLMv2ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutxlm-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_xlm = LayoutLMv2ForTokenClassification.from_pretrained(\"microsoft/layoutxlm-base\", config=xlm_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_xlm.save_pretrained(path_to_home + \"models/token_class_xlm_base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_xlm = LayoutLMv2ForTokenClassification.from_pretrained(path_to_home + \"models/token_class_xlm_base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "LayoutLMv2ForTokenClassification(\n  (layoutlmv2): LayoutLMv2Model(\n    (embeddings): LayoutLMv2Embeddings(\n      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768)\n      (x_position_embeddings): Embedding(1024, 128)\n      (y_position_embeddings): Embedding(1024, 128)\n      (h_position_embeddings): Embedding(1024, 128)\n      (w_position_embeddings): Embedding(1024, 128)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (visual): LayoutLMv2VisualBackbone(\n      (backbone): FPN(\n        (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (top_block): LastLevelMaxPool()\n        (bottom_up): ResNet(\n          (stem): BasicStem(\n            (conv1): Conv2d(\n              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n            )\n          )\n          (res2): Sequential(\n            (0): BottleneckBlock(\n              (shortcut): Conv2d(\n                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv1): Conv2d(\n                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n            )\n            (1): BottleneckBlock(\n              (conv1): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n            )\n            (2): BottleneckBlock(\n              (conv1): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n            )\n          )\n          (res3): Sequential(\n            (0): BottleneckBlock(\n              (shortcut): Conv2d(\n                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv1): Conv2d(\n                256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n            )\n            (1): BottleneckBlock(\n              (conv1): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n            )\n            (2): BottleneckBlock(\n              (conv1): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n            )\n            (3): BottleneckBlock(\n              (conv1): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n            )\n          )\n          (res4): Sequential(\n            (0): BottleneckBlock(\n              (shortcut): Conv2d(\n                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv1): Conv2d(\n                512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (1): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (2): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (3): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (4): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (5): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (6): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (7): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (8): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (9): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (10): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (11): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (12): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (13): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (14): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (15): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (16): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (17): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (18): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (19): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (20): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (21): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (22): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n          )\n          (res5): Sequential(\n            (0): BottleneckBlock(\n              (shortcut): Conv2d(\n                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv1): Conv2d(\n                1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n            )\n            (1): BottleneckBlock(\n              (conv1): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n            )\n            (2): BottleneckBlock(\n              (conv1): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n            )\n          )\n        )\n      )\n      (pool): AdaptiveAvgPool2d(output_size=[7, 7])\n    )\n    (visual_proj): Linear(in_features=256, out_features=768, bias=True)\n    (visual_LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (visual_dropout): Dropout(p=0.1, inplace=False)\n    (encoder): LayoutLMv2Encoder(\n      (layer): ModuleList(\n        (0): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): LayoutLMv2Pooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ds_receipts.set_format(type=\"torch\", device=device)\n",
    "model_xlm.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "config = {\"train_batch_size\": 4,\n",
    "          \"valid_batch_size\": 2,\n",
    "          \"weight_decay\": 0.1,\n",
    "          \"learning_rate\": 5e-5,\n",
    "          \"num_train_epochs\": 2,\n",
    "          \"seed\": 1,\n",
    "          \"save_checkpoint_steps\": 100}\n",
    "\n",
    "args = Namespace(**config)\n",
    "\n",
    "logging_file_path = path_to_home + \"log/logging/train.log\"\n",
    "wandb_dir = path_to_home +\"log/wandb\"\n",
    "tensorboard_dir = path_to_home + \"log/tensorboard\"\n",
    "hf_models_dir = path_to_home + \"models/receiptlayoutlm\"\n",
    "project_name = \"receiptlayoutlm\"\n",
    "user_name = \"sibrun\"\n",
    "hf_model = user_name + \"/\" + project_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(ds_receipts['train'], batch_size=args.train_batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(ds_receipts['test'], batch_size=args.valid_batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image torch.Size([4, 3, 224, 224])\n",
      "input_ids torch.Size([4, 512])\n",
      "bbox torch.Size([4, 512, 4])\n",
      "labels torch.Size([4, 512])\n",
      "attention_mask torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for k,v in batch.items():\n",
    "  print(k, v.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model_xlm.parameters(), lr=args.learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import logging\n",
    "#import wandb\n",
    "#import transformers\n",
    "#import datasets\n",
    "\n",
    "def setup_logging():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "        handlers=[logging.FileHandler(logging_file_path), logging.StreamHandler()])\n",
    "    #wandb.init(project=project_name_wandb,\n",
    "    #           config=args,\n",
    "    #           dir=wandb_dir,\n",
    "    #           settings=wandb.Settings(start_method=\"fork\"),\n",
    "    #           entity=\"sibrun\",\n",
    "    #           sync_tensorboard=True)\n",
    "    #run_name = wandb.run.name\n",
    "    tb_writer = SummaryWriter()\n",
    "    tb_writer.add_hparams(vars(args), {'0': 0})\n",
    "    logger.setLevel(logging.INFO)\n",
    "    #datasets.utils.logging.set_verbosity_debug()\n",
    "    #transformers.utils.logging.set_verbosity_info()\n",
    "    return logger, tb_writer #, run_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def log_metrics(step, metrics, tb_writer):\n",
    "    logger.info(f\"Step {step}: {metrics}\")\n",
    "    #wandb.log(metrics)\n",
    "    [tb_writer.add_scalar(k, v, step) for k, v in metrics.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model_xlm.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model_xlm(**batch)\n",
    "        losses.append(model_outputs.loss)\n",
    "    total_loss = torch.mean(torch.stack(losses))\n",
    "    try:\n",
    "        perplexity = torch.exp(total_loss)\n",
    "    except OverflowError:\n",
    "            perplexity = torch.tensor(float(\"inf\"))\n",
    "    return loss.item(), perplexity.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from random import seed\n",
    "seed(args.seed)\n",
    "\n",
    "logger, tb_writer = setup_logging()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/PycharmProjects/receiptlayoutlm/venv/lib/python3.9/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py:772: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.arange(\n",
      "/Users/simon/PycharmProjects/receiptlayoutlm/venv/lib/python3.9/site-packages/transformers/models/layoutlmv2/modeling_layoutlmv2.py:782: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.arange(\n",
      "03/13/2022 20:13:11 - INFO - __main__ - Step 0: {'steps': 0, 'loss/train': 1.6082464456558228}\n",
      "03/13/2022 20:13:11 - INFO - __main__ - Evaluating and saving model checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 0 steps: 1.6082464456558228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2022 20:17:35 - INFO - __main__ - Step 0: {'loss/eval': 1.6082464456558228, 'perplexity': 4.877651691436768}\n"
     ]
    },
    {
     "data": {
      "text/plain": "Upload file pytorch_model.bin:   0%|          | 32.0k/1.38G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c77377778630489698147f39237430b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m     log_metrics(step, {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss/eval\u001B[39m\u001B[38;5;124m'\u001B[39m: eval_loss, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mperplexity\u001B[39m\u001B[38;5;124m'\u001B[39m: perplexity}, tb_writer)\n\u001B[1;32m     16\u001B[0m     model_xlm\u001B[38;5;241m.\u001B[39msave_pretrained(hf_models_dir)\n\u001B[0;32m---> 17\u001B[0m     \u001B[43mmodel_xlm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhf_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstep \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mstep\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m model_xlm\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m     19\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/PycharmProjects/receiptlayoutlm/venv/lib/python3.9/site-packages/transformers/file_utils.py:2919\u001B[0m, in \u001B[0;36mPushToHubMixin.push_to_hub\u001B[0;34m(self, repo_path_or_name, repo_url, use_temp_dir, commit_message, organization, private, use_auth_token, **model_card_kwargs)\u001B[0m\n\u001B[1;32m   2917\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_model_card(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbase_model_card_args)\n\u001B[1;32m   2918\u001B[0m \u001B[38;5;66;03m# Commit and push!\u001B[39;00m\n\u001B[0;32m-> 2919\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_push_to_hub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_message\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2921\u001B[0m \u001B[38;5;66;03m# Clean up! Clean up! Everybody everywhere!\u001B[39;00m\n\u001B[1;32m   2922\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_temp_dir:\n",
      "File \u001B[0;32m~/PycharmProjects/receiptlayoutlm/venv/lib/python3.9/site-packages/transformers/file_utils.py:2999\u001B[0m, in \u001B[0;36mPushToHubMixin._push_to_hub\u001B[0;34m(cls, repo, commit_message)\u001B[0m\n\u001B[1;32m   2996\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2997\u001B[0m         commit_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madd model\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2999\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_message\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/receiptlayoutlm/venv/lib/python3.9/site-packages/huggingface_hub/repository.py:1251\u001B[0m, in \u001B[0;36mRepository.push_to_hub\u001B[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001B[0m\n\u001B[1;32m   1249\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgit_add(auto_lfs_track\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1250\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgit_commit(commit_message)\n\u001B[0;32m-> 1251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgit_push\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mupstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43morigin \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_branch\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mblocking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauto_lfs_prune\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauto_lfs_prune\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1255\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/receiptlayoutlm/venv/lib/python3.9/site-packages/huggingface_hub/repository.py:1010\u001B[0m, in \u001B[0;36mRepository.git_push\u001B[0;34m(self, upstream, blocking, auto_lfs_prune)\u001B[0m\n\u001B[1;32m   1001\u001B[0m process \u001B[38;5;241m=\u001B[39m subprocess\u001B[38;5;241m.\u001B[39mPopen(\n\u001B[1;32m   1002\u001B[0m     command\u001B[38;5;241m.\u001B[39msplit(),\n\u001B[1;32m   1003\u001B[0m     stderr\u001B[38;5;241m=\u001B[39msubprocess\u001B[38;5;241m.\u001B[39mPIPE,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1006\u001B[0m     cwd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocal_dir,\n\u001B[1;32m   1007\u001B[0m )\n\u001B[1;32m   1009\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m blocking:\n\u001B[0;32m-> 1010\u001B[0m     stdout, stderr \u001B[38;5;241m=\u001B[39m \u001B[43mprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcommunicate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1011\u001B[0m     return_code \u001B[38;5;241m=\u001B[39m process\u001B[38;5;241m.\u001B[39mpoll()\n\u001B[1;32m   1012\u001B[0m     process\u001B[38;5;241m.\u001B[39mkill()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py:1134\u001B[0m, in \u001B[0;36mPopen.communicate\u001B[0;34m(self, input, timeout)\u001B[0m\n\u001B[1;32m   1131\u001B[0m     endtime \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1133\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1134\u001B[0m     stdout, stderr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_communicate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendtime\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1135\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m   1136\u001B[0m     \u001B[38;5;66;03m# https://bugs.python.org/issue25942\u001B[39;00m\n\u001B[1;32m   1137\u001B[0m     \u001B[38;5;66;03m# See the detailed comment in .wait().\u001B[39;00m\n\u001B[1;32m   1138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py:1979\u001B[0m, in \u001B[0;36mPopen._communicate\u001B[0;34m(self, input, endtime, orig_timeout)\u001B[0m\n\u001B[1;32m   1972\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timeout(endtime, orig_timeout,\n\u001B[1;32m   1973\u001B[0m                         stdout, stderr,\n\u001B[1;32m   1974\u001B[0m                         skip_check_and_raise\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1975\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(  \u001B[38;5;66;03m# Impossible :)\u001B[39;00m\n\u001B[1;32m   1976\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   1977\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfailed to raise TimeoutExpired.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1979\u001B[0m ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1980\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001B[1;32m   1982\u001B[0m \u001B[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001B[39;00m\n\u001B[1;32m   1983\u001B[0m \u001B[38;5;66;03m# objects; they are no longer using C stdio!\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "model_xlm.train()\n",
    "for epoch in range(args.num_train_epochs):\n",
    "   print(\"Epoch:\", epoch)\n",
    "   for batch in train_dataloader:\n",
    "       optimizer.zero_grad()\n",
    "       outputs = model_xlm(**batch)\n",
    "       loss = outputs.loss\n",
    "       log_metrics(step, {'steps': step, 'loss/train': loss.item()}, tb_writer)\n",
    "       if step % 10 == 0:\n",
    "           print(f\"Loss after {step} steps: {loss.item()}\")\n",
    "       if step % args.save_checkpoint_steps == 0:\n",
    "           logger.info('Evaluating and saving model checkpoint')\n",
    "           eval_loss, perplexity = evaluate()\n",
    "           log_metrics(step, {'loss/eval': eval_loss, 'perplexity': perplexity}, tb_writer)\n",
    "           model_xlm.save_pretrained(hf_models_dir)\n",
    "           model_xlm.push_to_hub(hf_model, commit_message=f'step {step}')\n",
    "       model_xlm.train()\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       step += 1\n",
    "\n",
    "logger.info('Evaluating and saving model after training')\n",
    "eval_loss, perplexity = evaluate()\n",
    "log_metrics(step, {'loss/eval': eval_loss, 'perplexity': perplexity}, tb_writer)\n",
    "model_xlm.save_pretrained(hf_models_dir)\n",
    "model_xlm.push_to_hub(hf_model, commit_message='final model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}