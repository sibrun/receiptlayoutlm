{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "!sudo apt-get install git-lfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install git-lfs\n",
    "!pip install torch torchvision\n",
    "!pip install datasets transformers\n",
    "!pip install Pillow\n",
    "!pip install pytesseract\n",
    "!pip install sentencepiece\n",
    "!pip install wandb\n",
    "!pip install tensorflow tensorboard\n",
    "!pip install tensorboardX\n",
    "!pip install seqeval\n",
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "from huggingface_hub import Repository"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "path_to_home = \"../\"\n",
    "#path_to_home = \"./drive/MyDrive/receiptlayoutlm/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/PycharmProjects/receiptlayoutlm/code/../hugging_face_repo is already a clone of https://huggingface.co/sibrun/receiptlayoutlm. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "hf_repo = Repository(path_to_home + \"hugging_face_repo\", clone_from=\"https://huggingface.co/sibrun/receiptlayoutlm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "hf_repo = Repository(path_to_home + \"hugging_face_repo\")\n",
    "#hf_repo.git_pull()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'image': Sequence(feature=Sequence(feature=Sequence(feature=Value(dtype='uint8', id=None), length=-1, id=None), length=-1, id=None), length=-1, id=None),\n 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n 'bbox': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds_receipts = load_dataset(\"sibrun/receipts\", use_auth_token=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds_receipts.save_to_disk(path_to_home + \"datasets/ds_receipts_final\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds_receipts = load_from_disk(path_to_home + \"datasets/ds_receipts_final\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from datasets import Features, Array2D, Array3D, Sequence, Value\n",
    "max_length = 512\n",
    "features = Features({\n",
    "    'image': Array3D(dtype=\"uint8\", shape=(3, 224, 224)),\n",
    "    'input_ids': Sequence(feature=Value(dtype=\"int32\"), length=max_length),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(max_length, 4)),\n",
    "    'labels': Sequence(feature=Value(dtype=\"int64\"), length=max_length),\n",
    "    'attention_mask': Sequence(feature=Value(dtype=\"int8\"), length=max_length),\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../datasets/ds_receipts_final/train/cache-e5c271fb43f54ac8.arrow\n",
      "Loading cached processed dataset at ../datasets/ds_receipts_final/test/cache-c1bc42bb40029ecf.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'image': Array3D(shape=(3, 224, 224), dtype='uint8', id=None),\n 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=512, id=None),\n 'bbox': Array2D(shape=(512, 4), dtype='int64', id=None),\n 'labels': Sequence(feature=Value(dtype='int64', id=None), length=512, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=512, id=None)}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_receipts = ds_receipts.cast(features)\n",
    "ds_receipts['train'].features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "label_names = ['company', 'date', 'address', 'total']\n",
    "labels = ['O'] + label_names\n",
    "num_labels = len(labels)\n",
    "ids_to_labels = {k: v for k, v in enumerate(labels)}\n",
    "labels_to_ids = {v: k for k, v in enumerate(labels)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from transformers import LayoutLMv2ForTokenClassification\n",
    "\n",
    "xlm_config = AutoConfig.from_pretrained(\"microsoft/layoutxlm-base\",\n",
    "                                         num_labels=num_labels,\n",
    "                                         id2label=ids_to_labels,\n",
    "                                         label2id=labels_to_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutxlm-base were not used when initializing LayoutLMv2ForTokenClassification: ['layoutlmv2.visual.backbone.bottom_up.res4.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.stem.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv1.norm.num_batches_tracked']\n",
      "- This IS expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LayoutLMv2ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutxlm-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_xlm = LayoutLMv2ForTokenClassification.from_pretrained(\"microsoft/layoutxlm-base\", config=xlm_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_xlm.save_pretrained(path_to_home + \"models/token_class_xlm_base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_xlm = LayoutLMv2ForTokenClassification.from_pretrained(path_to_home + \"models/token_class_xlm_base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model_xlm = LayoutLMv2ForTokenClassification.from_pretrained(path_to_home + \"models/receiptlayoutlm\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "LayoutLMv2ForTokenClassification(\n  (layoutlmv2): LayoutLMv2Model(\n    (embeddings): LayoutLMv2Embeddings(\n      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768)\n      (x_position_embeddings): Embedding(1024, 128)\n      (y_position_embeddings): Embedding(1024, 128)\n      (h_position_embeddings): Embedding(1024, 128)\n      (w_position_embeddings): Embedding(1024, 128)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (visual): LayoutLMv2VisualBackbone(\n      (backbone): FPN(\n        (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (top_block): LastLevelMaxPool()\n        (bottom_up): ResNet(\n          (stem): BasicStem(\n            (conv1): Conv2d(\n              3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n            )\n          )\n          (res2): Sequential(\n            (0): BottleneckBlock(\n              (shortcut): Conv2d(\n                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv1): Conv2d(\n                64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n            )\n            (1): BottleneckBlock(\n              (conv1): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n            )\n            (2): BottleneckBlock(\n              (conv1): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n              )\n            )\n          )\n          (res3): Sequential(\n            (0): BottleneckBlock(\n              (shortcut): Conv2d(\n                256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv1): Conv2d(\n                256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n            )\n            (1): BottleneckBlock(\n              (conv1): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n            )\n            (2): BottleneckBlock(\n              (conv1): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n            )\n            (3): BottleneckBlock(\n              (conv1): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n              )\n            )\n          )\n          (res4): Sequential(\n            (0): BottleneckBlock(\n              (shortcut): Conv2d(\n                512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv1): Conv2d(\n                512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (1): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (2): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (3): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (4): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (5): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (6): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (7): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (8): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (9): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (10): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (11): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (12): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (13): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (14): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (15): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (16): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (17): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (18): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (19): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (20): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (21): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n            (22): BottleneckBlock(\n              (conv1): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n              )\n            )\n          )\n          (res5): Sequential(\n            (0): BottleneckBlock(\n              (shortcut): Conv2d(\n                1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv1): Conv2d(\n                1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n            )\n            (1): BottleneckBlock(\n              (conv1): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n            )\n            (2): BottleneckBlock(\n              (conv1): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv2): Conv2d(\n                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n              (conv3): Conv2d(\n                2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n                (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n              )\n            )\n          )\n        )\n      )\n      (pool): AdaptiveAvgPool2d(output_size=[7, 7])\n    )\n    (visual_proj): Linear(in_features=256, out_features=768, bias=True)\n    (visual_LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (visual_dropout): Dropout(p=0.1, inplace=False)\n    (encoder): LayoutLMv2Encoder(\n      (layer): ModuleList(\n        (0): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): LayoutLMv2Layer(\n          (attention): LayoutLMv2Attention(\n            (self): LayoutLMv2SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): LayoutLMv2Pooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ds_receipts.set_format(type=\"torch\", device=device)\n",
    "model_xlm.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "config = {\"train_batch_size\": 24,\n",
    "          \"valid_batch_size\": 24,\n",
    "          \"weight_decay\": 0.1,\n",
    "          \"learning_rate\": 5e-5,\n",
    "          \"num_train_epochs\": 6,\n",
    "          \"seed\": 1,\n",
    "          \"log_loss_steps\": 1,\n",
    "          \"eval_steps\": 20,\n",
    "          \"save_checkpoint_steps\": 40,\n",
    "          \"push_checkpoint_steps\": 80,\n",
    "          \"push_to_hub_train\": False,\n",
    "          \"push_to_hub_end\": True,\n",
    "          \"max_eval_steps\": 1000}\n",
    "\n",
    "args = Namespace(**config)\n",
    "\n",
    "logging_file_path = path_to_home + \"log/logging/train.log\"\n",
    "wandb_dir = path_to_home +\"log/wandb\"\n",
    "tensorboard_dir = path_to_home + \"log/tensorboard\"\n",
    "project_name = \"receiptlayoutlm\"\n",
    "user_name = \"sibrun\"\n",
    "hf_model_path = path_to_home + \"models/\" + project_name\n",
    "hf_model_name = user_name + \"/\" + project_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(ds_receipts['train'], batch_size=args.train_batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(ds_receipts['test'], batch_size=args.valid_batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image torch.Size([16, 3, 224, 224])\n",
      "input_ids torch.Size([16, 512])\n",
      "bbox torch.Size([16, 512, 4])\n",
      "labels torch.Size([16, 512])\n",
      "attention_mask torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for k,v in batch.items():\n",
    "  print(k, v.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model_xlm.parameters(), lr=args.learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import logging\n",
    "#import wandb\n",
    "#import transformers\n",
    "#import datasets\n",
    "\n",
    "def setup_logging():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    "        handlers=[logging.FileHandler(logging_file_path), logging.StreamHandler()])\n",
    "    #wandb.init(project=project_name_wandb,\n",
    "    #           config=args,\n",
    "    #           dir=wandb_dir,\n",
    "    #           settings=wandb.Settings(start_method=\"fork\"),\n",
    "    #           entity=\"sibrun\",\n",
    "    #           sync_tensorboard=True)\n",
    "    #run_name = wandb.run.name\n",
    "    tb_writer = SummaryWriter(log_dir=tensorboard_dir)\n",
    "    tb_writer.add_hparams(vars(args), {'0': 0})\n",
    "    logger.setLevel(logging.INFO)\n",
    "    #datasets.utils.logging.set_verbosity_debug()\n",
    "    #transformers.utils.logging.set_verbosity_info()\n",
    "    return logger, tb_writer #, run_name\n",
    "\n",
    "def log_scores(step, scores, tb_writer):\n",
    "    logger.info(f\"Step {step}: {scores}\")\n",
    "    #wandb.log(scores)\n",
    "    [tb_writer.add_scalar(k, v, step) for k, v in scores.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "import collections, functools, operator\n",
    "\n",
    "seqeval_metrics = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(predictions_list, labels_list, metrics=seqeval_metrics, id2label=ids_to_labels):\n",
    "    relevant_predictions_list = [[id2label[p] for (p, l) in zip(predictions, labels) if l != -100]\n",
    "                   for (predictions, labels) in zip(predictions_list, labels_list)]\n",
    "    relevant_labels_list = [[id2label[l] for (p, l) in zip(predictions, labels) if l != -100]\n",
    "                   for (predictions, labels) in zip(predictions_list, labels_list)]\n",
    "\n",
    "    scores = metrics.compute(predictions=relevant_predictions_list, references=relevant_labels_list)\n",
    "    overall_scores = {'precision': scores['overall_precision'],\n",
    "                      'recall':  scores['overall_recall'],\n",
    "                      'f1': scores['overall_f1'],\n",
    "                      'accuracy': scores['overall_accuracy']}\n",
    "    return overall_scores\n",
    "\n",
    "def evaluate():\n",
    "    model_xlm.eval()\n",
    "    loss_list = []\n",
    "    predictions_list = []\n",
    "    labels_list = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        if step >= args.max_eval_steps:\n",
    "            break\n",
    "        labels_list.append(batch['labels'].flatten().tolist())\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model_xlm(**batch)\n",
    "        loss_list.append(model_outputs.loss)\n",
    "        predictions = np.argmax(model_outputs.logits, axis=-1)\n",
    "        predictions_list.append(predictions.flatten().tolist())\n",
    "    total_loss = torch.mean(torch.stack(loss_list))\n",
    "    total_scores = compute_metrics(predictions_list, labels_list)\n",
    "    total_scores['loss/eval'] = total_loss.item()\n",
    "    return total_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "from random import seed\n",
    "seed(args.seed)\n",
    "\n",
    "logger, tb_writer = setup_logging()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "step = 0\n",
    "model_xlm.train()\n",
    "for epoch in range(args.num_train_epochs):\n",
    "    log_scores(step, {'Epoch': epoch}, tb_writer)\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model_xlm(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step % args.log_loss_steps == 0:\n",
    "            log_scores(step, {'loss/train': loss.item()}, tb_writer)\n",
    "        step += 1\n",
    "        if step % args.eval_steps == 0:\n",
    "            logger.info('Evaluating')\n",
    "            scores = evaluate()\n",
    "            log_scores(step, scores, tb_writer)\n",
    "        if step % args.save_checkpoint_steps == 0:\n",
    "            logger.info('Saving model checkpoint')\n",
    "            model_xlm.save_pretrained(hf_model_path)\n",
    "        if args.push_to_hub_train and step % args.push_checkpoint_steps == 0:\n",
    "            logger.info('Pushing model checkpoint')\n",
    "            model_xlm.push_to_hub(hf_model_name, commit_message=f'step {step}')\n",
    "\n",
    "\n",
    "logger.info('Evaluating and saving model after training')\n",
    "scores = evaluate()\n",
    "log_scores(step, scores, tb_writer)\n",
    "model_xlm.save_pretrained(hf_model_path)\n",
    "if args.push_to_hub_end:\n",
    "    model_xlm.push_to_hub(hf_model_name, commit_message='final model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}